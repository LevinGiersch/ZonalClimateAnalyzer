{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e57ced7c-8cb8-4d42-9799-5578dc44c5c9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import zipfile\n",
    "import gzip\n",
    "import filetype\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "from itertools import chain\n",
    "\n",
    "from urllib.parse import urljoin, urlparse\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import folium\n",
    "import geopandas as gpd\n",
    "from pyproj import CRS\n",
    "import rasterio\n",
    "from rasterio.crs import CRS\n",
    "from rasterstats import zonal_stats\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Use a non-GUI backend. Prevents \"QSocketNotifier: Can only be used with threads started with QThread\" message in cmd.\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef5e71bb-ba1c-4dc5-abfc-2c808f26d008",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Create subfolders\n",
    "\n",
    "Path('climate_environment_CDC_grids_germany_annual').mkdir(exist_ok=True)\n",
    "Path('data_info').mkdir(exist_ok=True)\n",
    "Path('output').mkdir(exist_ok=True)\n",
    "Path('shp').mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0de6b8f-d6b3-43f7-935f-cc23f13c82dc",
   "metadata": {},
   "source": [
    "# Get Shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0867040f-bfbc-4373-aa08-aca3eff1645a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def check_crs(shapefile:str):\n",
    "    '''\n",
    "    Takes a path to a Shapefile (as String) as Input.\n",
    "    Reads shapefile.\n",
    "    Returns True if it has a valid CRS,\n",
    "    Returns False if it die NOT have a valid CRS.\n",
    "    '''\n",
    "\n",
    "    # Load the shapefile\n",
    "    gdf = gpd.read_file(shapefile)\n",
    "    \n",
    "    # Check if CRS is defined\n",
    "    valid_crs = gdf.crs\n",
    "    if valid_crs:\n",
    "        print(\"\\nCRS is defined:\", gdf.crs)\n",
    "        return True\n",
    "    else:\n",
    "        print(\"\\nCRS is NOT defined.\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc0f1783-cd16-4134-99d5-3e3bf23eb2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shp():\n",
    "    '''\n",
    "    Lets the user input a path to the shapefile in the terminal.\n",
    "    Checks if the path leads to a shapefile.\n",
    "    Checks if the shapefile has a valid CRS.\n",
    "    Gives feedback depending on the user input.\n",
    "    Returns path to the shapefile if Valid shp and CRS are found.\n",
    "    '''\n",
    "\n",
    "    print('\\n'+'#'*64)\n",
    "    print('\\nThis Program lets you analyze the climate history of any area within Germany.')\n",
    "    print('You only need a shapefile defining the area you want to analyze.')\n",
    "\n",
    "    while True:  # This function runs until input is valid\n",
    "        shp_input = input('\\nEnter the path to the shapefile here: ').strip()\n",
    "        shp_path = Path(shp_input)\n",
    "\n",
    "        # If the input is a file path\n",
    "        if shp_path.is_file() and shp_path.suffix.lower() == '.shp':\n",
    "            try:\n",
    "                gdf = gpd.read_file(shp_path)\n",
    "                if gdf.crs:\n",
    "                    print('Valid shapefile with valid CRS found.')\n",
    "                    return shp_path\n",
    "                else:\n",
    "                    print('Shapefile found, but CRS is not defined.')\n",
    "                    continue\n",
    "            except Exception as e:\n",
    "                print(f'Error reading shapefile: {e}')\n",
    "                continue\n",
    "\n",
    "        # If the input is a folder path, search for any .shp file inside\n",
    "        elif shp_path.is_dir():\n",
    "            shp_files = list(shp_path.glob(\"*.shp\"))\n",
    "            if shp_files:\n",
    "                print(f'Found shapefiles: {[f.name for f in shp_files]}. \\nPlease append the filename to the path and try again.\\n')\n",
    "                continue\n",
    "            else:\n",
    "                print('No shapefile found in the folder.')\n",
    "                continue\n",
    "\n",
    "        else:\n",
    "            print('Invalid path or not a shapefile.')\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfb1b16-14eb-4202-8252-9dc7d4079885",
   "metadata": {},
   "source": [
    "# Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ed8e5ac-2bca-419f-88e7-bf44304bcb68",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def check_if_already_downloaded(raster_links:list[str]) -> bool:\n",
    "    \"\"\"\n",
    "    Returns True if all raster_links have already been downloaded as .tif files.\n",
    "    \"\"\"\n",
    "\n",
    "    # Folder where files might be saved\n",
    "    folder = Path.cwd() / 'climate_environment_CDC_grids_germany_annual'\n",
    "\n",
    "    # Return False if folder is empty\n",
    "    if not any(folder.iterdir()):\n",
    "        return False\n",
    "    \n",
    "    # List of files in the folder\n",
    "    files = [f for f in folder.iterdir() if f.is_file()]\n",
    "\n",
    "    # Check if every filename (without .tif) occures in any item in the raster_links list\n",
    "    for f in files:\n",
    "        if not any(f.stem in r for r in raster_links):\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5116a7f-4b48-43f7-b958-8e7cf1ac6081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_of_dwd_data(file_types=['.asc.gz', '.pdf', '.zip']):\n",
    "    '''\n",
    "    Creates a list containing all dwd files to download.\n",
    "\n",
    "    Parameters:\n",
    "        file_types: string, ending that correspondes to the filetype that we want to download\n",
    "\n",
    "    Returns:\n",
    "        links: list containing links to all files to download\n",
    "    '''\n",
    "\n",
    "    # Get list of all download locations containing the data to download:\n",
    "    base_download_location = 'https://opendata.dwd.de/climate_environment/CDC/grids_germany/annual/'\n",
    "    folder_download_locations = [\n",
    "        'air_temperature_max/',\n",
    "        'air_temperature_mean/',\n",
    "        'air_temperature_min/',\n",
    "        'drought_index/',\n",
    "        #'erosivity/',\n",
    "        'frost_days/',\n",
    "        'hot_days/', \n",
    "        'ice_days/',\n",
    "        'phenology/',\n",
    "        'precipGE10mm_days/',\n",
    "        'precipGE20mm_days/',\n",
    "        'precipGE30mm_days/',\n",
    "        'precipitation/',\n",
    "        #'radiation_diffuse/',\n",
    "        #'radiation_direct/',\n",
    "        #'radiation_global/',\n",
    "        'snowcover_days/',\n",
    "        'summer_days/',\n",
    "        'sunshine_duration/',\n",
    "        'vegetation_begin/',\n",
    "        'vegetation_end/'\n",
    "    ]\n",
    "    download_locations = [base_download_location+f for f in folder_download_locations]\n",
    "\n",
    "    # Create a list containing all links\n",
    "    links = []\n",
    "    for location in download_locations:\n",
    "        response = requests.get(location)\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(f'\\nFailed to retrieve the webpage: {location}')\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Build absolute URLs\n",
    "        found = [\n",
    "            location + a['href']\n",
    "            for a in soup.find_all('a', href=True)\n",
    "            if a['href'].lower().endswith(tuple(file_types))\n",
    "        ]\n",
    "        links.append(found)\n",
    "\n",
    "    links_flattend = list(chain.from_iterable(links))\n",
    "\n",
    "    return links_flattend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7252c1a-3b30-4af2-8917-7c0c3dd8b263",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def download_dwd_data(links:list[str], dest_dir:str, timeout:int=30):\n",
    "    \"\"\"\n",
    "    Download files from a list of full URLs into a target directory.\n",
    "\n",
    "    Parameters:\n",
    "        links (list[str]): List of full download URLs.\n",
    "        dest_dir (str or Path): Local directory where the files will be saved.\n",
    "        timeout (int, optional): Maximum number of seconds to wait for a server response. Defaults to 30.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    dest = Path(dest_dir)\n",
    "    dest.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for file_url in tqdm(links,\n",
    "                     desc='',\n",
    "                     bar_format='{l_bar}{bar:40}| ({n_fmt}/{total_fmt}) Downloading files.',\n",
    "                     ncols=120):\n",
    "        filename = Path(urlparse(file_url).path).name\n",
    "        file_path = dest / filename\n",
    "\n",
    "        with requests.get(file_url, stream=True, timeout=timeout) as r:\n",
    "            if r.status_code != 200:\n",
    "                print(f'\\nFehler {r.status_code}: {file_url}')\n",
    "                continue\n",
    "            with file_path.open('wb') as f:\n",
    "                for chunk in r.iter_content(chunk_size=8192):\n",
    "                    if chunk:\n",
    "                        f.write(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0d2700-b5be-40d4-b9d4-2808934c1bba",
   "metadata": {},
   "source": [
    "# Process the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31db0912-0a46-4d74-adc0-3ef4aeb21651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_of_files(folder:str, file_type='.gz'):\n",
    "    '''\n",
    "    Returns list containing all filesnames in folder with the ending file_type.\n",
    "\n",
    "    Args:\n",
    "        folder: string, path in filesystem including target folder\n",
    "        file_type: string, ending that correspondes to the filetype that we want to download\n",
    "    Return:\n",
    "        List of all files of file_type within folder\n",
    "    '''\n",
    "\n",
    "    folder = Path(folder)\n",
    "    files = sorted([\n",
    "        str(f) for f in folder.iterdir()\n",
    "        if f.is_file() and \"\".join(f.suffixes).lower().endswith(file_type.lower())\n",
    "    ])\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd39d8d3-99a1-40fc-9350-eda11edfe561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_dwd_file(file:str):\n",
    "        \"\"\"\n",
    "        Takes filename as string as input.\n",
    "        Removes everything except for the core name and the year from the dwd filename.\n",
    "        Returns new filename as string.\n",
    "        \"\"\"\n",
    "        file = file.replace('grids_germany_annual_', '')\n",
    "        file = file.removesuffix('.asc.gz')\n",
    "        if file.endswith('_1917') or file.endswith('_2017'):\n",
    "            pass\n",
    "        else:\n",
    "            file = file.removesuffix('17')\n",
    "        file = file.removesuffix('_')\n",
    "        file = file+'.asc'\n",
    "\n",
    "        return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "daee8dfb-7fad-4697-9188-159f50934419",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def decompress_file(file:str):\n",
    "    \"\"\"\n",
    "    Decompress files and saves a copy in the same folder.\n",
    "\n",
    "    Args:\n",
    "        file (str): path to file (input file)\n",
    "    Return:\n",
    "        decompressed_file (str): Path to decompressed file (output file)\n",
    "    \"\"\"\n",
    "\n",
    "    # Check Filetype:\n",
    "    ft = filetype.guess(file)\n",
    "    ft_ext = ft.extension\n",
    "\n",
    "    if ft_ext == 'asc' or ft_ext == 'tif':\n",
    "        print(f'Filetype is already {ft_ext}, no decompression needed')\n",
    "\n",
    "    elif ft_ext == 'gz':\n",
    "        decompressed_file = Path(rename_dwd_file(file))            # Name for output file\n",
    "        with gzip.open(file, mode='rb') as f_in:                   # Open .gz file and decompress it\n",
    "            with open(decompressed_file, mode='wb') as f_out:      # Create decompressed file\n",
    "                shutil.copyfileobj(f_in, f_out)                    # Copy content of compressed file to decompressed file\n",
    "\n",
    "    # Unpack the mis‑labelled “…asc.gz” archive (which is really a ZIP)\n",
    "    elif ft_ext == 'zip':\n",
    "        decompressed_file = Path(rename_dwd_file(file))         # Name for output file\n",
    "        zip_path = Path(file).expanduser().resolve()\n",
    "    \n",
    "        with zipfile.ZipFile(zip_path) as zf:\n",
    "            # find the first .asc inside the archive\n",
    "            asc_members = [m for m in zf.namelist() if m.lower().endswith(\".asc\")]\n",
    "            if not asc_members:\n",
    "                raise ValueError(\"No .asc file found in archive.\")\n",
    "            # write it directly to the desired location\n",
    "            with zf.open(asc_members[0]) as src, decompressed_file.open(\"wb\") as dst:\n",
    "                dst.write(src.read())\n",
    "                \n",
    "    else:\n",
    "        print(f'Error while decompressing File: {file}. \\nFiletype {ft_ext} is not supported. \\nSupported filetypes are: .gz, .zip, .asc or .tif\\n')\n",
    "        raise TypeError(f'Error while decompressing File. Filetype is not supported. Supported filetypes are: .gz, .zip, .asc or .tif')\n",
    "\n",
    "    #print(f'decompress_file: Successfully decompressed \\n\"{file}\" to \\n\"{decompressed_file}\".\\n')\n",
    "\n",
    "    return decompressed_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1d7ef3b-0b3d-428d-bd3c-9debb017b865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def asc_to_tif_add_crs(asc_input:str, prj_txt:str):\n",
    "    \"\"\"\n",
    "    Takes asc_input, adds crs (from prj.txt), saves it as .tif in the same folder.\n",
    "\n",
    "    Args:\n",
    "        asc_input (str): path to asc file (input file)\n",
    "        prj_txt (str): path to prj file (text file that contains projection information)\n",
    "    \n",
    "    Returns:\n",
    "        tif_output (tif): path/to/output.tif file\n",
    "    \"\"\"\n",
    "\n",
    "    # CRS from .prj_file\n",
    "    with open(prj_txt, 'r', encoding='utf-8') as f:\n",
    "        wkt = f.read()\n",
    "    crs = CRS.from_wkt(wkt)\n",
    "\n",
    "    # Read the .asc file\n",
    "    with rasterio.open(asc_input) as src:\n",
    "        data = src.read(1)\n",
    "        profile = src.profile\n",
    "\n",
    "    # Update Profile with CRS\n",
    "    profile.update({\n",
    "        'driver': 'GTiff',\n",
    "        'crs': crs,\n",
    "        'dtype': rasterio.float32,\n",
    "        'compress': 'lzw'\n",
    "    })\n",
    "\n",
    "    tif_output = asc_input.replace('.asc', '')+'.tif'\n",
    "\n",
    "    # Write to a new GeoTIFF file with CRS assigned\n",
    "    with rasterio.open(tif_output, 'w', **profile) as dst:\n",
    "        dst.write(data.astype(rasterio.float32), 1)\n",
    "    \n",
    "    #print(f'asc_to_tif_add_crs: Successfully transformed \\n\"{asc_input}\" to \\n\"{tif_output}\" \\nand added {crs}.\\n')\n",
    "\n",
    "    return tif_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cc12932-cd16-4180-91ec-0b2a8cdfa63a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def delete_raster_files(folder_path:str):\n",
    "    \"\"\"\n",
    "    Deletes all .asc, .asc.gz and .zip files within the folder..\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): Path to folder containing the files.\n",
    "    \"\"\"\n",
    "    \n",
    "    folder = Path(folder_path)\n",
    "    patterns = ['*.asc', '*.asc.gz', '*.zip']\n",
    "    deleted_files = 0\n",
    "\n",
    "    for pattern in patterns:\n",
    "        for file in folder.glob(pattern):\n",
    "            file.unlink()\n",
    "            deleted_files += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55748775-bea6-483a-926b-18bef2b976d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_shp_crs(shp_input:str, prj_txt:str):\n",
    "    \"\"\"\n",
    "    Takes shp_input, transforms to crs (from prj.txt), outputs as shp_output\n",
    "\n",
    "    Args:\n",
    "        shp_input (str): path to shp file (input file)\n",
    "        prj_txt (str): path to prj file (text file that contains projection information)\n",
    "    \n",
    "    Returns:\n",
    "        shp_output (str): path/to/output.tif file\n",
    "    \"\"\"\n",
    "\n",
    "    # CRS from .prj_file\n",
    "    with open(prj_txt, 'r', encoding='utf-8') as f:\n",
    "        wkt = f.read()\n",
    "    target_crs = CRS.from_wkt(wkt)\n",
    "\n",
    "    # Read Shapefile\n",
    "    gdf = gpd.read_file(shp_input)\n",
    "\n",
    "    # Check if CRS is defined\n",
    "    if gdf.crs is None:\n",
    "        raise ValueError('Input shapefile crs is undefined. Set correct crs. (eg. gdf.set_crs())')\n",
    "\n",
    "    # Transform shp_input to target_crs\n",
    "    gdf_transformed = gdf.to_crs(target_crs)\n",
    "\n",
    "    # Create Output Folder\n",
    "    shp_folder_path = Path.cwd() / 'shp'\n",
    "    shp_folder_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Define output name\n",
    "    shp_output = str(shp_folder_path / Path(str(shp_input).replace('.shp', '')+'_'+str(target_crs).replace(':','')+'.shp').name)\n",
    "\n",
    "    # Save transformed shp to shp_output\n",
    "    gdf_transformed.to_file(shp_output, encoding='utf-8')\n",
    "\n",
    "    #print(f'change_shp_crs: Successfully copied \\n\"{shp_input}\" to \\n\"{shp_output}\" \\nand added {target_crs}.\\n')\n",
    "\n",
    "    return shp_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8db26026-7aad-4eb2-bd82-2d98c2c2636a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def dissolve_shp(shp_input:str):\n",
    "    \"\"\"\n",
    "    Takes shp_input, dissolve all polygon features into one, outputs as dissolved_shp\n",
    "\n",
    "    Args:\n",
    "        shp_input (str): path to shp file (input file)\n",
    "    \n",
    "    Returns:\n",
    "        shp_output (str): path/to/output.tif file\n",
    "    \"\"\"\n",
    "\n",
    "    # Read Shapefile\n",
    "    gdf = gpd.read_file(shp_input)\n",
    "\n",
    "    # Dissolve features in gdf\n",
    "    gdf_dissolved = gdf.dissolve()\n",
    "\n",
    "    # Create Output Folder\n",
    "    shp_folder_path = Path.cwd() / 'shp'\n",
    "    shp_folder_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Define output name\n",
    "    shp_output = str(shp_folder_path / Path(str(shp_input).replace('.shp', '')+'_dissolved'+'.shp').name)\n",
    "\n",
    "    # Save transformed shp to shp_output\n",
    "    gdf_dissolved.to_file(shp_output, encoding='utf-8')\n",
    "    \n",
    "    return shp_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2e9b97b-fc56-48a2-a5e9-ddb1c1090045",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def calculate_zonal_stats(shp:str, tif:str):\n",
    "    \"\"\"\n",
    "    Calculates zonal stats of the tif for each feature in the shp.\n",
    "\n",
    "    Args:\n",
    "        shp (str): path to shp file\n",
    "        tif (str): path to tif file\n",
    "    \n",
    "    Returns:\n",
    "        stats (list[dict]): list of dictionarys which contain min, max, mean and count of the raster data for each poly.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set all_touched to False if you want to include only raster-cells that are completely within the shapefile.\n",
    "    stats = zonal_stats(shp, tif, all_touched=True)\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc251bbb-8564-4920-bcda-c3f8483ae957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zonal_climate_analysis(shp_input:str, raster_folder:str, prj_file:str):\n",
    "    \"\"\"\n",
    "    Perform rasterstats calculation on shp_input with every raster file in the raster_folder.\n",
    "\n",
    "    Args:\n",
    "        shp_input (str): path to shp file (input file) to perform calculations on\n",
    "        raster_folder (str): path to folder containing all raster files to perform the rasterstats calculations with. has to be in .asc.gz file format\n",
    "        prj_txt (str): path to prj file (text file that contains projection information)\n",
    "    \n",
    "    Creates:\n",
    "        rasterstats_dict (dict{str:[{}]}): dict containing the name of the raster file as key and the corresponding rasterstats as a list of dicts as values.\n",
    "    Returns:\n",
    "        json_output_path_name (str): path to the created json file conatining rasterstats calculations.\n",
    "        shp_crs_dissolved (str): path to the dissolved shapefile with transformed crs the rasterstats where calculated on.\n",
    "    \"\"\"\n",
    "\n",
    "    # Prepare shapefile:\n",
    "    shp_crs = change_shp_crs(shp_input, prj_file)\n",
    "    shp_crs_dissolved = dissolve_shp(shp_crs)\n",
    "    \n",
    "    # Create list of compessed .asc.gz rasterfiles:\n",
    "    files_asc_gz = list_of_files(raster_folder, file_type='.asc.gz')\n",
    "    \n",
    "    if len(files_asc_gz) != 0:\n",
    "        # Decompress rasterfiles:\n",
    "        for f in tqdm(files_asc_gz,\n",
    "                      desc='',\n",
    "                      bar_format='{l_bar}{bar:40}| ({n_fmt}/{total_fmt}) Decompressing files.',\n",
    "                      ncols=120):\n",
    "            decompress_file(f)\n",
    "    else:\n",
    "        print('Files are already decompressed.')\n",
    "\n",
    "    # Create list of decompressed .asc rasterfiles:\n",
    "    files_asc = list_of_files(raster_folder, file_type='.asc')\n",
    "\n",
    "    if len(files_asc) != 0:\n",
    "        # Transform decompressed files to tif and add crs:\n",
    "        for f in tqdm(files_asc,\n",
    "                      desc='',\n",
    "                      bar_format='{l_bar}{bar:40}| ({n_fmt}/{total_fmt}) Transforming files to the right format.',\n",
    "                      ncols=120):\n",
    "            asc_to_tif_add_crs(f, prj_file)\n",
    "    else:\n",
    "        print('Files are already transformed to the right format.')\n",
    "\n",
    "    # Create list .tif rasterfiles\n",
    "    files_tif = list_of_files(raster_folder, file_type='.tif')\n",
    "\n",
    "    # Create list containing rasterstats:\n",
    "    rasterstats_list = []\n",
    "\n",
    "    # Iterate over files_tif and perform rasterstats calculations on each rasterfile and the shapefile:\n",
    "    for f in tqdm(files_tif,\n",
    "                  desc='',\n",
    "                  bar_format='{l_bar}{bar:40}| ({n_fmt}/{total_fmt}) Calculating rasterstats.',\n",
    "                  ncols=120):\n",
    "        rasterstats_list.append(calculate_zonal_stats(shp_crs_dissolved, f)) # Append rasterstats to rasterstats_list\n",
    "\n",
    "    # Combine rasterstats and the name of the raster the stats are calculated with\n",
    "    raster_path = str(Path.cwd() / 'climate_environment_CDC_grids_germany_annual')\n",
    "    filenames = [Path(fn).with_suffix('').name for fn in files_tif] # Ceate list with filenames without path and type  \n",
    "\n",
    "    # Delete deprecated files\n",
    "    delete_raster_files(raster_path)\n",
    "\n",
    "    # Create dict\n",
    "    rasterstats_dict = dict(zip(filenames, rasterstats_list))\n",
    "\n",
    "    # Convert rasterstats_dict to better json format:\n",
    "    rasterstats_json = {}\n",
    "\n",
    "    for key, value in rasterstats_dict.items():\n",
    "        name = key[:-5]\n",
    "        year = key[-4:]\n",
    "        if name not in rasterstats_json:\n",
    "            rasterstats_json[name] = {}\n",
    "        rasterstats_json[name][year] = value\n",
    "\n",
    "    #pprint(rasterstats_json)\n",
    "\n",
    "    # Export dict as json:\n",
    "    path_to_shp = Path(shp_crs_dissolved)\n",
    "    shp_name = path_to_shp.name\n",
    "    json_output_path_name = shp_name.replace('.shp','')+'_rasterstats.json'\n",
    "    \n",
    "    with open(json_output_path_name, 'w', encoding='utf-8') as rs_json:\n",
    "        json.dump(rasterstats_json, rs_json)\n",
    "\n",
    "    return json_output_path_name, shp_crs_dissolved"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0b6bc2-c6a5-417d-bbcf-28914cd256c5",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1185a48-1f1d-4dc2-8359-8e8d07ed63be",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def years_values(parameter_name:str):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        parameter_name (str): key in rasterstats.json dictionary\n",
    "    Returns:\n",
    "        title (str): parameter_name\n",
    "        years (list): list of years\n",
    "        values_max (list): list of max values\n",
    "        values_mean (list): list of mean values\n",
    "        values_min (list): list of min values\n",
    "    \"\"\"\n",
    "\n",
    "    # Title:\n",
    "    title = parameter_name\n",
    "\n",
    "    # Years:\n",
    "    years = []\n",
    "    for year in rs[title]:\n",
    "        years.append(year)\n",
    "\n",
    "    # Values max:\n",
    "    values_max = []\n",
    "    for year in rs[parameter_name].values():\n",
    "        for entry in year:\n",
    "            values_max.append(entry['max'])\n",
    "\n",
    "    # Values mean:\n",
    "    values_mean = []\n",
    "    for year in rs[parameter_name].values():\n",
    "        for entry in year:\n",
    "            values_mean.append(entry['mean'])\n",
    "\n",
    "    # Values mean:\n",
    "    values_min = []\n",
    "    for year in rs[parameter_name].values():\n",
    "        for entry in year:\n",
    "            values_min.append(entry['min'])\n",
    "    \n",
    "    return title, years, values_max, values_mean, values_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b040b01-9f9f-4122-945d-64ceb9abf44c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def create_map(shapefile:str):\n",
    "    '''\n",
    "    Takes path to shapefile as string as input.\n",
    "    Creates interactive map as html.\n",
    "    Adds area and perimeter as tooltips on hover in the html map.\n",
    "    '''\n",
    "    \n",
    "    shp_path = Path(shapefile)\n",
    "    gdf = gpd.read_file(shapefile)\n",
    "    if gdf.crs is None:\n",
    "        raise ValueError(\"CRS is missing. Set a CRS before running.\")\n",
    "\n",
    "    # Compute in a local metric CRS\n",
    "    gdf_m = gdf.to_crs(gdf.estimate_utm_crs())\n",
    "    is_poly = gdf_m.geom_type.str.contains(\"polygon\", case=False, na=False)\n",
    "    gdf[\"area_km2\"] = (gdf_m.area.where(is_poly)) / 1_000_000\n",
    "    gdf[\"perim_km\"] = (gdf_m.length.where(is_poly)) / 1_000\n",
    "    gdf[\"shapefile\"] = shp_path.stem\n",
    "\n",
    "    # interactive map\n",
    "    m = gdf.to_crs(4326).explore(\n",
    "        tooltip=[\"shapefile\", \"area_km2\", \"perim_km\"],\n",
    "        popup=False\n",
    "    )\n",
    "    \n",
    "    # Save Map\n",
    "    mapname = shp_name+'_'+'map.html'\n",
    "    map_folder_path = Path.cwd() / 'output'\n",
    "    map_folder_path.mkdir(parents=True, exist_ok=True)\n",
    "    map_path = str(map_folder_path / mapname)\n",
    "    m.save(map_path)\n",
    "    print(f'Successfully created and saved map: {mapname}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c357741f-2315-488e-8043-423d7ce09751",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_air_temp_min_mean_max():\n",
    "    # Air Temp min mean max\n",
    "    plt.close()\n",
    "\n",
    "    # Create a figure containing a single Axes.\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # List oft startyears\n",
    "    startyears = []\n",
    "    \n",
    "    # Max Temp\n",
    "    title, years, values_max, t_max, values_min = years_values('air_temp_max')\n",
    "    t_max = [t_max[i]/10 for i in range(len(t_max))]                            # 1/10 so it is in degrees noch in degrees/10\n",
    "    startyears.append(years[0])\n",
    "\n",
    "    # Mean Temp\n",
    "    title, years, values_max, t_mean, values_min = years_values('air_temp_mean')\n",
    "    t_mean = [t_mean[i]/10 for i in range(len(t_mean))]\n",
    "    startyears.append(years[0])\n",
    "\n",
    "    # Min Temp\n",
    "    title, years, values_max, t_min, values_min = years_values('air_temp_min')\n",
    "    t_min = [t_min[i]/10 for i in range(len(t_min))]\n",
    "    startyears.append(years[0])\n",
    "\n",
    "    # Crop to the same start-year\n",
    "    common_startyear = int(max(startyears))\n",
    "    t_max  = [v for y, v in zip(map(int, years), t_max)  if y >= common_startyear]\n",
    "    t_mean = [v for y, v in zip(map(int, years), t_mean) if y >= common_startyear]\n",
    "    t_min  = [v for y, v in zip(map(int, years), t_min)  if y >= common_startyear]\n",
    "\n",
    "    # Plot\n",
    "    ax.plot(years, t_max, color='red', label='Maximale Lufttemperatur')\n",
    "    ax.plot(years, t_mean, color='Black', label='Mittlere Lufttemperatur')\n",
    "    ax.plot(years, t_min, color='blue', label='Minimale Lufttemperatur')\n",
    "\n",
    "    # Fill between lines\n",
    "    ax.fill_between(years, t_max, t_mean, color='red', alpha=0.25)\n",
    "    ax.fill_between(years, t_mean, t_min, color='blue', alpha=0.25)\n",
    "\n",
    "    # Gridlines:\n",
    "    ax.grid(color='lightgrey', linewidth=0.5)\n",
    "\n",
    "    # Plot Customization\n",
    "    fig.set_size_inches(6.3*2, 3.15*2)\n",
    "    ax.set_ylim([0, max(t_max)*1.2])\n",
    "    ax.set_xlim(['1954', max(years)])\n",
    "    #ax.set_title('Eis- und Frosttage')\n",
    "    ax.set_xlabel('Jahre')\n",
    "    ax.set_ylabel('Temperatur in °C')\n",
    "    ax.legend(loc='upper right')\n",
    "    plt.xticks(rotation=45)\n",
    "    for label in ax.xaxis.get_ticklabels():  # Iterate over all ticklabels\n",
    "        if int(label.get_text()) % 5 == 0:   # Check if ticklabel is dividable by 5\n",
    "            label.set_visible(True)\n",
    "        else:\n",
    "            label.set_visible(False)\n",
    "\n",
    "    # Save Plot\n",
    "    plotname = shp_name+'_'+'min_mean_max_temp'+'_plot.png'\n",
    "    plot_folder_path = Path.cwd() / 'output'\n",
    "    plot_folder_path.mkdir(parents=True, exist_ok=True)\n",
    "    plot_path = str(plot_folder_path / plotname)\n",
    "    plt.savefig(plot_path, bbox_inches='tight', dpi=300)\n",
    "    print(f'Successfully created and saved plot: {plotname}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "195673e1-5b8f-4cf9-9560-64bce71bcc2d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_frost_ice_days():\n",
    "    # Frost and Ice Days\n",
    "    plt.close()\n",
    "\n",
    "    # Create a figure containing a single Axes.\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Ice Days\n",
    "    title, years, values_max, values_mean_id, values_min = years_values('ice_days')\n",
    "\n",
    "    # Frost Days\n",
    "    title, years, values_max, values_mean_fd, values_min = years_values('frost_days')\n",
    "\n",
    "    # List containing 365 (days per year) as many times as there are years (upper limit)\n",
    "    days_in_year_max = [365]*len(years)\n",
    "\n",
    "    # List containing 365 (days per year) as many times as there are years (lower limit)\n",
    "    days_in_year_min = [0]*len(years)\n",
    "\n",
    "    # Plot\n",
    "    ax.plot(years, values_mean_fd, color='lightblue', label='Frosttage (min 0°C)')\n",
    "    ax.plot(years, values_mean_id, color='darkblue', label='Eistage (max 0°C)')\n",
    "\n",
    "    # Fill between lines\n",
    "    ax.fill_between(years, values_mean_fd, values_mean_id, color='lightblue', alpha=0.25)\n",
    "    ax.fill_between(years, values_mean_id, days_in_year_min, color='darkblue', alpha=0.25)\n",
    "\n",
    "    # Gridlines:\n",
    "    ax.grid(color='lightgrey', linewidth=0.5)\n",
    "\n",
    "    # Plot Customization\n",
    "    fig.set_size_inches(6.3*2, 3.15*2)\n",
    "    ax.set_ylim([0, max(values_mean_fd)*1.2])\n",
    "    ax.set_xlim(['1954', max(years)])\n",
    "    #ax.set_title('Eis- und Frosttage')\n",
    "    ax.set_xlabel('Jahre')\n",
    "    ax.set_ylabel('Tage')\n",
    "    ax.legend(loc='upper right')\n",
    "    plt.xticks(rotation=45)\n",
    "    for label in ax.xaxis.get_ticklabels():  # Iterate over all ticklabels\n",
    "        if int(label.get_text()) % 5 == 0:   # Check if ticklabel is dividable by 5\n",
    "            label.set_visible(True)\n",
    "        else:\n",
    "            label.set_visible(False)\n",
    "\n",
    "    # Save Plot\n",
    "    plotname = shp_name+'_'+'ice_frost_days'+'_plot.png'\n",
    "    plot_folder_path = Path.cwd() / 'output'\n",
    "    plot_folder_path.mkdir(parents=True, exist_ok=True)\n",
    "    plot_path = str(plot_folder_path / plotname)\n",
    "    plt.savefig(plot_path, bbox_inches='tight', dpi=300)\n",
    "    print(f'Successfully created and saved plot: {plotname}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "759343ea-09b3-4ec6-a1bb-971b743e586d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_snowcover_days():\n",
    "    # Snowcover Days\n",
    "    plt.close()\n",
    "\n",
    "    # Create a figure containing a single Axes.\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Snowcover Days\n",
    "    title, years, values_max, values_mean_snd, values_min = years_values('snowcover_days')\n",
    "\n",
    "    # List containing 365 (days per year) as many times as there are years (upper limit)\n",
    "    days_in_year_max = [365]*len(years)\n",
    "\n",
    "    # List containing 365 (days per year) as many times as there are years (lower limit)\n",
    "    days_in_year_min = [0]*len(years)\n",
    "\n",
    "    # Plot\n",
    "    ax.plot(years, values_mean_snd, color='lightblue', label='Tage mit > 1cm Schneehöhe')\n",
    "\n",
    "    # Fill between lines\n",
    "    ax.fill_between(years, values_mean_snd, days_in_year_min, color='lightblue', alpha=0.25)\n",
    "    \n",
    "    # Gridlines:\n",
    "    ax.grid(color='lightgrey', linewidth=0.5)\n",
    "\n",
    "    # Plot Customization\n",
    "    fig.set_size_inches(6.3*2, 3.15*2)\n",
    "    ax.set_ylim([0, max(values_mean_snd)*1.2])\n",
    "    ax.set_xlim(['1954', max(years)])\n",
    "    #ax.set_title('Eis- und Frosttage')\n",
    "    ax.set_xlabel('Jahre')\n",
    "    ax.set_ylabel('Tage')\n",
    "    ax.legend(loc='upper right')\n",
    "    plt.xticks(rotation=45)\n",
    "    for label in ax.xaxis.get_ticklabels():  # Iterate over all ticklabels\n",
    "        if int(label.get_text()) % 5 == 0:   # Check if ticklabel is dividable by 5\n",
    "            label.set_visible(True)\n",
    "        else:\n",
    "            label.set_visible(False)\n",
    "\n",
    "    # Save Plot\n",
    "    plotname = shp_name+'_'+'snowcover_days'+'_plot.png'\n",
    "    plot_folder_path = Path.cwd() / 'output'\n",
    "    plot_folder_path.mkdir(parents=True, exist_ok=True)\n",
    "    plot_path = str(plot_folder_path / plotname)\n",
    "    plt.savefig(plot_path, bbox_inches='tight', dpi=300)\n",
    "    print(f'Successfully created and saved plot: {plotname}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "283e11ed-ecde-4c8a-9e64-a156828764ba",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_summer_hot_days():\n",
    "    # Summer and Hot Days\n",
    "    plt.close()\n",
    "\n",
    "    # Create a figure containing a single Axes.\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Ice Days\n",
    "    title, years, values_max, values_mean_sd, values_min = years_values('summer_days')\n",
    "\n",
    "    # Frost Days\n",
    "    title, years, values_max, values_mean_hd, values_min = years_values('hot_days')\n",
    "\n",
    "    # List containing 365 (days per year) as many times as there are years (upper limit)\n",
    "    days_in_year_max = [365]*len(years)\n",
    "\n",
    "    # List containing 365 (days per year) as many times as there are years (lower limit)\n",
    "    days_in_year_min = [0]*len(years)\n",
    "\n",
    "    # Plot\n",
    "    ax.plot(years, values_mean_sd, color='orange', label='Sommertage (max 25°C)')\n",
    "    ax.plot(years, values_mean_hd, color='red', label='Heiße Tage (max 30°C)')\n",
    "\n",
    "    # Fill between lines\n",
    "    ax.fill_between(years, values_mean_hd, values_mean_sd, color='orange', alpha=0.25)\n",
    "    ax.fill_between(years, values_mean_sd, days_in_year_min, color='red', alpha=0.25)\n",
    "\n",
    "    # Gridlines:\n",
    "    ax.grid(color='lightgrey', linewidth=0.5)\n",
    "\n",
    "    # Plot Customization\n",
    "    fig.set_size_inches(6.3*2, 3.15*2)\n",
    "    ax.set_ylim([0, max(values_mean_sd)*1.2])\n",
    "    ax.set_xlim(['1954', max(years)])\n",
    "    #ax.set_title('Heiße- und Sommertage')\n",
    "    ax.set_xlabel('Jahre')\n",
    "    ax.set_ylabel('Tage')\n",
    "    ax.legend(loc='upper right')\n",
    "    plt.xticks(rotation=45)\n",
    "    for label in ax.xaxis.get_ticklabels():  # Iterate over all ticklabels\n",
    "        if int(label.get_text()) % 5 == 0:   # Check if ticklabel is dividable by 5\n",
    "            label.set_visible(True)\n",
    "        else:\n",
    "            label.set_visible(False)\n",
    "\n",
    "    # Save Plot\n",
    "    plotname = shp_name+'_'+'summer_hot_days'+'_plot.png'\n",
    "    plot_folder_path = Path.cwd() / 'output'\n",
    "    plot_folder_path.mkdir(parents=True, exist_ok=True)\n",
    "    plot_path = str(plot_folder_path / plotname)\n",
    "    plt.savefig(plot_path, bbox_inches='tight', dpi=300)\n",
    "    print(f'Successfully created and saved plot: {plotname}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df8dc0a4-bd90-4997-9a38-705e7c4d38a7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_precipitaion():\n",
    "    # Precipitation\n",
    "    plt.close()\n",
    "\n",
    "    # Create a figure containing a single Axes.\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Precipitation\n",
    "    title, years, values_max, values_mean_pp, values_min = years_values('precipitation')\n",
    "\n",
    "    # Precipitation\n",
    "    title, yearsdi, values_max, values_mean_di, values_min = years_values('drought_index')\n",
    "    values_mean_di = [di*10 for di in values_mean_di]\n",
    "\n",
    "    # Plot\n",
    "    ax.plot(years, values_mean_pp, color='blue', label='Niederschlag in mm')\n",
    "    ax.fill_between(years, values_mean_pp, color='blue', alpha=0.25)\n",
    "    ax.plot(yearsdi, values_mean_di, color='orange', label='Trockenheitsindex (mm/°C)')\n",
    "\n",
    "    # Gridlines:\n",
    "    ax.grid(color='lightgrey', linewidth=0.5)\n",
    "\n",
    "    # Plot Customization\n",
    "    fig.set_size_inches(6.3*2, 3.15*2)\n",
    "    ax.set_ylim([0, max(values_mean_pp)*1.2])\n",
    "    ax.set_xlim(['1954', max(years)])\n",
    "    #ax.set_title('Niederschlag und Trockenheitsindex')\n",
    "    ax.set_xlabel('Jahre')\n",
    "    ax.set_ylabel('Niederschlag (mm)')\n",
    "    ax.legend(loc='upper right')\n",
    "    plt.xticks(rotation=45)\n",
    "    for label in ax.xaxis.get_ticklabels():  # Iterate over all ticklabels\n",
    "        if int(label.get_text()) % 5 == 0:   # Check if ticklabel is dividable by 5\n",
    "            label.set_visible(True)\n",
    "        else:\n",
    "            label.set_visible(False)\n",
    "\n",
    "    # Save Plot\n",
    "    plotname = shp_name+'_'+'precipitation_drought'+'_plot.png'\n",
    "    plot_folder_path = Path.cwd() / 'output'\n",
    "    plot_folder_path.mkdir(parents=True, exist_ok=True)\n",
    "    plot_path = str(plot_folder_path / plotname)\n",
    "    plt.savefig(plot_path, bbox_inches='tight', dpi=300)\n",
    "    print(f'Successfully created and saved plot: {plotname}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b20af0d3-8b61-47a8-9e45-6e5e425b3ef8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_precipitaion_days():\n",
    "    # Precipitation Days\n",
    "    plt.close()\n",
    "\n",
    "    # Create a figure containing a single Axes.\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # 10mm\n",
    "    title, years, values_max, p10, values_min = years_values('precipGE10mm_days')\n",
    "\n",
    "    # 20mm\n",
    "    title, years, values_max, p20, values_min = years_values('precipGE20mm_days')\n",
    "    #p1020 = [p10[i]+p20[i] for i in range(len(p10))]\n",
    "\n",
    "    # 30mm\n",
    "    title, years, values_max, p30, values_min = years_values('precipGE30mm_days')\n",
    "    #p102030 = [p10[i]+p20[i]+p30[i] for i in range(len(p10))]\n",
    "\n",
    "    # List containing 365 (days per year) as many times as there are years (lower limit)\n",
    "    days_in_year_min = [0]*len(years)\n",
    "\n",
    "    # Plot\n",
    "    ax.plot(years, p10, color='lightblue', label='Anzahl der Tage mit Niederschlagshöhe >= 10 mm')\n",
    "    ax.plot(years, p20, color='blue', label='Anzahl der Tage mit Niederschlagshöhe >= 20 mm')\n",
    "    ax.plot(years, p30, color='darkblue', label='Anzahl der Tage mit Niederschlagshöhe >= 30 mm')\n",
    "\n",
    "    # Fill between lines\n",
    "    ax.fill_between(years, p10, p20, color='lightblue', alpha=0.25)\n",
    "    ax.fill_between(years, p20, p30, color='blue', alpha=0.25)\n",
    "    ax.fill_between(years, p30, days_in_year_min, color='darkblue', alpha=0.25)\n",
    "\n",
    "    # Gridlines:\n",
    "    ax.grid(color='lightgrey', linewidth=0.5)\n",
    "\n",
    "    # Plot customization\n",
    "    fig.set_size_inches(6.3*2, 3.15*2)\n",
    "    ax.set_ylim([0, max(p10)*1.2])\n",
    "    ax.set_xlim(['1954', max(years)])\n",
    "    #ax.set_title('Anzahl der Niederschlagstage')\n",
    "    ax.set_xlabel('Jahre')\n",
    "    ax.set_ylabel('Tage')\n",
    "    ax.legend(loc='upper right')\n",
    "    plt.xticks(rotation=45)\n",
    "    for label in ax.xaxis.get_ticklabels():  # Iterate over all ticklabels\n",
    "        if int(label.get_text()) % 5 == 0:   # Check if ticklabel is dividable by 5\n",
    "            label.set_visible(True)\n",
    "        else:\n",
    "            label.set_visible(False)\n",
    "\n",
    "    # Save Plot\n",
    "    plotname = shp_name+'_'+'precip_days'+'_plot.png'\n",
    "    plot_folder_path = Path.cwd() / 'output'\n",
    "    plot_folder_path.mkdir(parents=True, exist_ok=True)\n",
    "    plot_path = str(plot_folder_path / plotname)\n",
    "    plt.savefig(plot_path, bbox_inches='tight', dpi=300)\n",
    "    print(f'Successfully created and saved plot: {plotname}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f6d6089-1fda-4817-b256-04138157dd55",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_sunshine_duration():\n",
    "    # Sunshine Duration\n",
    "    plt.close()\n",
    "\n",
    "    # Create a figure containing a single Axes.\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Sunshine Duration\n",
    "    title, years, values_max, values_mean_sd, values_min = years_values('sunshine_duration')\n",
    "    values_mean_sd = [sd/365 for sd in values_mean_sd]\n",
    "\n",
    "    # Plot\n",
    "    ax.plot(years, values_mean_sd, color='orange', label='Durchschnittliche Sonnenstunden pro Tag')\n",
    "    ax.fill_between(years, values_mean_sd, color='orange', alpha=0.25)\n",
    "\n",
    "    # Gridlines:\n",
    "    ax.grid(color='lightgrey', linewidth=0.5)\n",
    "\n",
    "    # Plot Customization\n",
    "    fig.set_size_inches(6.3*2, 3.15*2)\n",
    "    ax.set_ylim([0, max(values_mean_sd)*1.2])\n",
    "    ax.set_xlim([min(years), max(years)])\n",
    "    #ax.set_title('Niederschlag und Trockenheitsindex')\n",
    "    ax.set_xlabel('Jahre')\n",
    "    ax.set_ylabel('Sonnenstunden pro Tag')\n",
    "    ax.legend(loc='upper right')\n",
    "    plt.xticks(rotation=45)\n",
    "    for label in ax.xaxis.get_ticklabels():  # Iterate over all ticklabels\n",
    "        if int(label.get_text()) % 5 == 0:   # Check if ticklabel is dividable by 5\n",
    "            label.set_visible(True)\n",
    "        else:\n",
    "            label.set_visible(False)\n",
    "\n",
    "    # Save Plot\n",
    "    plotname = shp_name+'_'+'sunshine_duration'+'_plot.png'\n",
    "    plot_folder_path = Path.cwd() / 'output'\n",
    "    plot_folder_path.mkdir(parents=True, exist_ok=True)\n",
    "    plot_path = str(plot_folder_path / plotname)\n",
    "    plt.savefig(plot_path, bbox_inches='tight', dpi=300)\n",
    "    print(f'Successfully created and saved plot: {plotname}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34ce0b69-308c-46cb-a348-672498dedc2d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_vegetation_begin_end():\n",
    "    # Vegetation begin and vegetation end\n",
    "    plt.close()\n",
    "\n",
    "    # Create a figure containing a single Axes.\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Vegetation begin line\n",
    "    title, years, values_max, values_mean_b, values_min = years_values('vegetation_begin')\n",
    "\n",
    "    # Vegetation end line\n",
    "    title, years, values_max, values_mean_e, values_min = years_values('vegetation_end')\n",
    "\n",
    "    # List containing 365 (days per year) as many times as there are years (upper limit)\n",
    "    days_in_year_max = [365]*len(years)\n",
    "\n",
    "    # List containing 365 (days per year) as many times as there are years (lower limit)\n",
    "    days_in_year_min = [0]*len(years)\n",
    "\n",
    "    # Plot\n",
    "    ax.plot(years, values_mean_e, color='red', label='Ende der vegetativen Phase')\n",
    "    ax.plot(years, values_mean_b, color='green', label='Begin der vegetativen Phase')\n",
    "\n",
    "    # Marking the beginning of the seasons\n",
    "    #ax.axhline(y=335, color='lightblue', linestyle='--', label='Winterbeginn')\n",
    "    #ax.axhline(y=244, color='orange', linestyle='--', label='Herbstbeginn')\n",
    "    #ax.axhline(y=152, color='darkgreen', linestyle='--', label='Sommerbeginn')\n",
    "    #ax.axhline(y=60, color='lightgreen', linestyle='--', label='Frühlingsbeginn')\n",
    "\n",
    "    # Fill between lines\n",
    "    ax.fill_between(years, values_mean_e, values_mean_b, color='green', alpha=0.25, label='Vegetative Phase')\n",
    "\n",
    "    # Gridlines:\n",
    "    ax.grid(color='lightgrey', linewidth=0.5)\n",
    "\n",
    "    # Plot Customization\n",
    "    fig.set_size_inches(6.3*2, 3.15*2)\n",
    "    ax.set_ylim([0, 365])\n",
    "    ax.set_xlim([min(years), max(years)])\n",
    "    #ax.set_title('Vegetative Phase')\n",
    "    ax.set_xlabel('Jahre')\n",
    "    ax.set_ylabel('Tage')\n",
    "    ax.legend(loc='upper right')\n",
    "    plt.xticks(rotation=45)\n",
    "    for label in ax.xaxis.get_ticklabels():  # Iterate over all ticklabels\n",
    "        if int(label.get_text()) % 5 == 0:   # Check if ticklabel is dividable by 5\n",
    "            label.set_visible(True)\n",
    "        else:\n",
    "            label.set_visible(False)\n",
    "\n",
    "    # Add month ticks on right side\n",
    "    ax2 = ax.twinx()\n",
    "    month_days = [0, 31, 59, 90, 120, 151, 181, 212, 243, 273, 304, 334]\n",
    "    month_labels = [\"Jan\", \"Feb\", \"Mär\", \"Apr\", \"Mai\", \"Jun\", \n",
    "                    \"Jul\", \"Aug\", \"Sep\", \"Okt\", \"Nov\", \"Dez\"]\n",
    "    ax2.set_ylim(ax.get_ylim())\n",
    "    ax2.set_yticks(month_days)\n",
    "    ax2.set_yticklabels(month_labels)\n",
    "    ax2.set_ylabel(\"Monatsbeginn\")\n",
    "\n",
    "    # Save Plot\n",
    "    plotname = shp_name+'_'+'vegetativ_phase'+'_plot.png'\n",
    "    plot_folder_path = Path.cwd() / 'output'\n",
    "    plot_folder_path.mkdir(parents=True, exist_ok=True)\n",
    "    plot_path = str(plot_folder_path / plotname)\n",
    "    plt.savefig(plot_path, bbox_inches='tight', dpi=300)\n",
    "    print(f'Successfully created and saved plot: {plotname}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2412da44-0535-4599-9581-efe9b4e50e01",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_vegetation_phase_length():\n",
    "    # Vegetation phase length\n",
    "    plt.close()\n",
    "\n",
    "    # Create a figure containing a single Axes.\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Vegetation begin line\n",
    "    title, years, values_max, values_mean_b, values_min = years_values('vegetation_begin')\n",
    "\n",
    "    # Vegetation end line\n",
    "    title, years, values_max, values_mean_e, values_min = years_values('vegetation_end')\n",
    "\n",
    "    # Vegetation phase length\n",
    "    veg_len = [values_mean_e[i]-values_mean_b[i] for i in range(len(years))]\n",
    "\n",
    "    # List containing 365 (days per year) as many times as there are years (upper limit)\n",
    "    days_in_year_max = [365]*len(years)\n",
    "\n",
    "    # List containing 365 (days per year) as many times as there are years (lower limit)\n",
    "    days_in_year_min = [0]*len(years)\n",
    "\n",
    "    # Plot\n",
    "    ax.plot(years, veg_len, color='green', label='Vegetative Phase')\n",
    "\n",
    "    # Fill between lines\n",
    "    ax.fill_between(years, veg_len, days_in_year_min, color='green', alpha=0.25)\n",
    "\n",
    "    # Gridlines:\n",
    "    ax.grid(color='lightgrey', linewidth=0.5)\n",
    "\n",
    "    # Plot Customization\n",
    "    fig.set_size_inches(6.3*2, 3.15*2)\n",
    "    ax.set_ylim([0, 365])\n",
    "    ax.set_xlim([min(years), max(years)])\n",
    "    #ax.set_title('Länge der vegetativen Phase')\n",
    "    ax.set_xlabel('Jahre')\n",
    "    ax.set_ylabel('Tage')\n",
    "    ax.legend(loc='upper right')\n",
    "    plt.xticks(rotation=45)\n",
    "    for label in ax.xaxis.get_ticklabels():  # Iterate over all ticklabels\n",
    "        if int(label.get_text()) % 5 == 0:   # Check if ticklabel is dividable by 5\n",
    "            label.set_visible(True)\n",
    "        else:\n",
    "            label.set_visible(False)\n",
    "\n",
    "    # Save Plot\n",
    "    plotname = shp_name+'_'+'vegetativ_phase_len'+'_plot.png'\n",
    "    plot_folder_path = Path.cwd() / 'output'\n",
    "    plot_folder_path.mkdir(parents=True, exist_ok=True)\n",
    "    plot_path = str(plot_folder_path / plotname)\n",
    "    plt.savefig(plot_path, bbox_inches='tight', dpi=300)\n",
    "    print(f'Successfully created and saved plot: {plotname}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b837b46-46ea-4c9e-bd0f-611dc7eb7205",
   "metadata": {},
   "source": [
    "# Run the Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b924b103-e7a9-4d2d-99cd-da81ce4a43f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################################################################\n",
      "\n",
      "This Program lets you analyze the climate history of any area within Germany.\n",
      "You only need a shapefile defining the area you want to analyze.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter the path to the shapefile here:  /home/luser/Documents/Temporary/brodo.shp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid shapefile with valid CRS found.\n"
     ]
    }
   ],
   "source": [
    "# Get the shapefile to analyze\n",
    "# /home/luser/Documents/Temporary/brodo.shp\n",
    "\n",
    "shp = get_shp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1142e3bc-5a8d-4932-8100-4d7321ad4174",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Download the data:\n",
      "Download the PDF files containing informations about the DWD data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| (35/35) Downloading files.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download the Rasterfiles:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|██████████████▌                         | (473/1298) Downloading files."
     ]
    }
   ],
   "source": [
    "# Download the data\n",
    "\n",
    "print('\\nDownload the data:')\n",
    "\n",
    "pdf_links = list_of_dwd_data(file_types=['.pdf'])\n",
    "raster_links = list_of_dwd_data(file_types=['.asc.gz', '.zip'])\n",
    "\n",
    "# Download if not already downloaded\n",
    "if check_if_already_downloaded(raster_links) is True:\n",
    "    print('All files are already downloaded.')\n",
    "    \n",
    "else:\n",
    "    print('Download the PDF files containing informations about the DWD data:')\n",
    "    download_dwd_data(pdf_links, 'data_info')\n",
    "    \n",
    "    print('Download the Rasterfiles:')\n",
    "    download_dwd_data(raster_links, 'climate_environment_CDC_grids_germany_annual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7059d7-f75d-42fb-b836-8036f0f71770",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Process the Data\n",
    "\n",
    "print('\\nProcess the data:')\n",
    "\n",
    "raster_path = str(Path.cwd() / 'climate_environment_CDC_grids_germany_annual')\n",
    "prj_file = 'gk3.prj'\n",
    "\n",
    "rasterstats_json, shp_crs_dissolved = zonal_climate_analysis(shp, raster_path, prj_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25f6efb-7a6a-48b9-ade5-228a3de15da7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Load Rasterstats JSON\n",
    "\n",
    "input_file = rasterstats_json # Created with zonal_climate_analysis(shp_input, raster_folder, prj_file)\n",
    "\n",
    "# Open rasterstats_dict.json file\n",
    "with open(input_file) as json_file:\n",
    "    rs = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde3b490-ab04-4492-8772-9ff1b4adb8bc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Create Maps and Plots\n",
    "\n",
    "print('\\nCreating Map and Plots:')\n",
    "\n",
    "shp_name = shp.stem\n",
    "\n",
    "# Create Map\n",
    "create_map(shp_crs_dissolved)\n",
    "\n",
    "# Create Plots\n",
    "plot_air_temp_min_mean_max()\n",
    "plot_frost_ice_days()\n",
    "plot_snowcover_days()\n",
    "plot_summer_hot_days()\n",
    "plot_precipitaion()\n",
    "plot_precipitaion_days()\n",
    "plot_sunshine_duration()\n",
    "plot_vegetation_begin_end()\n",
    "plot_vegetation_phase_length()\n",
    "\n",
    "print('\\nFinished!')\n",
    "print(f'\\nMap and plots are saved here: \\n{Path.cwd() / 'output'}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
